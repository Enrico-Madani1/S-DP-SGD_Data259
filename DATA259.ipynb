{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from opacus import PrivacyEngine\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  \n",
       "0          2174             0              40  United-States  \n",
       "1             0             0              13  United-States  \n",
       "2             0             0              40  United-States  \n",
       "3             0             0              40  United-States  \n",
       "4             0             0              40           Cuba  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE MODEL (No DP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8510594738458389\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      7414\n",
      "           1       0.74      0.59      0.65      2355\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = y.iloc[:, 0]\n",
    "# Strip spaces and remove periods\n",
    "y = y.str.strip().str.replace('.', '', regex=False)\n",
    "\n",
    "# Map both <=50K and <50K to 0; >=50K and >50K to 1\n",
    "y = y.replace({\n",
    "    '<=50K': 0,\n",
    "    '<50K': 0,\n",
    "    '>=50K': 1,\n",
    "    '>50K': 1\n",
    "})\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_metrics(X_test, y_true, y_pred, feature):\n",
    "    df_eval = X_test.copy()\n",
    "    df_eval['y_true'] = y_true\n",
    "    df_eval['y_pred'] = y_pred\n",
    "    \n",
    "    groups = df_eval[feature].unique()\n",
    "    metrics = []\n",
    "\n",
    "    for g in groups:\n",
    "        mask = df_eval[feature] == g\n",
    "        y_t = df_eval.loc[mask, 'y_true']\n",
    "        y_p = df_eval.loc[mask, 'y_pred']\n",
    "\n",
    "        # Positive prediction rate (Demographic Parity)\n",
    "        pos_rate = np.mean(y_p)\n",
    "\n",
    "        # True Positive Rate (Equal Opportunity)\n",
    "        tp = np.sum((y_p == 1) & (y_t == 1))\n",
    "        fn = np.sum((y_p == 0) & (y_t == 1))\n",
    "        tpr = tp / (tp + fn + 1e-10)\n",
    "\n",
    "        # False Positive Rate (Equalized Odds)\n",
    "        fp = np.sum((y_p == 1) & (y_t == 0))\n",
    "        tn = np.sum((y_p == 0) & (y_t == 0))\n",
    "        fpr = fp / (fp + tn + 1e-10)\n",
    "\n",
    "        # Accuracy\n",
    "        acc = np.mean(y_p == y_t)\n",
    "\n",
    "        metrics.append({\n",
    "            'group': g,\n",
    "            'positive_rate': pos_rate,\n",
    "            'TPR': tpr,\n",
    "            'FPR': fpr,\n",
    "            'accuracy': acc\n",
    "        })\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics)\n",
    "    print(f\"\\n=== Fairness by {feature} ===\")\n",
    "    print(df_metrics)\n",
    "\n",
    "    # Group gaps\n",
    "    max_min_gap = df_metrics[['positive_rate', 'TPR', 'FPR', 'accuracy']].max() - df_metrics[['positive_rate', 'TPR', 'FPR', 'accuracy']].min()\n",
    "    print(\"\\nGaps between groups:\")\n",
    "    print(max_min_gap)\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_full(name, model, X_model_input, y_true, X_sensitive, fairness_metrics_func=fairness_metrics):\n",
    "    \"\"\"\n",
    "    Evaluates a model (PyTorch DP/non-DP or sklearn) with standard metrics and fairness metrics.\n",
    "\n",
    "    Args:\n",
    "        name (str): Model name (for printing)\n",
    "        model: sklearn model or PyTorch nn.Module\n",
    "        X_model_input: np.ndarray or torch.Tensor input for the model\n",
    "        y_true: array-like, true labels\n",
    "        X_sensitive: pd.DataFrame with sensitive features (e.g., 'sex', 'race') for fairness\n",
    "        fairness_metrics_func: function to compute fairness metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # Detect if PyTorch model\n",
    "    is_torch_model = isinstance(model, torch.nn.Module)\n",
    "\n",
    "    if is_torch_model:\n",
    "        # Ensure tensor input\n",
    "        if not torch.is_tensor(X_model_input):\n",
    "            X_model_input = torch.tensor(X_model_input, dtype=torch.float32)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_model_input)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "            y_pred = np.argmax(outputs.cpu().numpy(), axis=1)\n",
    "    else:\n",
    "        # sklearn model\n",
    "        y_pred = model.predict(X_model_input)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            probs = model.predict_proba(X_model_input)[:, 1]\n",
    "        else:\n",
    "            probs = y_pred  # fallback if predict_proba not available\n",
    "\n",
    "    # Standard metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    print(f\"\\n=== Evaluation for {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(f\"AUC: {auc:.3f}\")\n",
    "\n",
    "    # Fairness metrics\n",
    "    sex_metrics = race_metrics = None\n",
    "    if fairness_metrics_func and X_sensitive is not None:\n",
    "        if 'sex' in X_sensitive.columns:\n",
    "            sex_metrics = fairness_metrics_func(X_sensitive, y_true, y_pred, 'sex')\n",
    "        if 'race' in X_sensitive.columns:\n",
    "            race_metrics = fairness_metrics_func(X_sensitive, y_true, y_pred, 'race')\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"auc\": auc,\n",
    "        \"sex_metrics\": sex_metrics,\n",
    "        \"race_metrics\": race_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation for No DP Logistic Regression ===\n",
      "Accuracy: 0.851\n",
      "AUC: 0.906\n",
      "\n",
      "=== Fairness by sex ===\n",
      "    group  positive_rate       TPR       FPR  accuracy\n",
      "0    Male       0.248623  0.600503  0.094589  0.812576\n",
      "1  Female       0.072688  0.506849  0.017434  0.928859\n",
      "\n",
      "Gaps between groups:\n",
      "positive_rate    0.175935\n",
      "TPR              0.093653\n",
      "FPR              0.077155\n",
      "accuracy         0.116282\n",
      "dtype: float64\n",
      "\n",
      "=== Fairness by race ===\n",
      "                group  positive_rate       TPR       FPR  accuracy\n",
      "0               White       0.203071  0.594747  0.068493  0.845388\n",
      "1               Black       0.077813  0.421488  0.027711  0.902208\n",
      "2  Amer-Indian-Eskimo       0.052083  0.375000  0.022727  0.927083\n",
      "3  Asian-Pac-Islander       0.264151  0.651163  0.120690  0.817610\n",
      "4               Other       0.059701  0.250000  0.033898  0.880597\n",
      "\n",
      "Gaps between groups:\n",
      "positive_rate    0.212068\n",
      "TPR              0.401163\n",
      "FPR              0.097962\n",
      "accuracy         0.109473\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# For non-DP model\n",
    "results_no_dp = evaluate_model_full(\n",
    "    name=\"No DP Logistic Regression\",\n",
    "    model=clf,                   # sklearn or PyTorch model\n",
    "    X_model_input=X_test_tensor if isinstance(clf, torch.nn.Module) else X_test, \n",
    "    y_true=y_test,\n",
    "    X_sensitive=X_test           # original DataFrame with sensitive features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model predicts that men are more likely to earn over $50K than women, which could reflect real income patterns but could also show bias.\n",
    "- It’s better at correctly identifying men who earn over $50K than women who do.\n",
    "- The model falsely labels men as rich more often than women.\n",
    "- Interestingly, it’s more accurate overall for women, possibly because fewer women are predicted as high earners, reducing some errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DP-SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enricoalmadani/anaconda3/lib/python3.10/site-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done\n",
      "Epoch 2 done\n",
      "Epoch 3 done\n",
      "Epoch 4 done\n",
      "Epoch 5 done\n",
      "Epoch 6 done\n",
      "Epoch 7 done\n",
      "Epoch 8 done\n",
      "Epoch 9 done\n",
      "Epoch 10 done\n",
      "DP-SGD Logistic Regression Test Accuracy: 0.841744\n",
      "Achieved epsilon (for DP-SGD): 0.088116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enricoalmadani/anaconda3/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocess features with your existing preprocessor\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Convert to torch tensors (handle sparse output from OneHotEncoder if any)\n",
    "def to_tensor(x):\n",
    "    if hasattr(x, \"toarray\"):\n",
    "        return torch.tensor(x.toarray(), dtype=torch.float32)\n",
    "    return torch.tensor(x, dtype=torch.float32)\n",
    "\n",
    "X_train_tensor = to_tensor(X_train_processed)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = to_tensor(X_test_processed)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define logistic regression model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LogisticRegressionModel(X_train_tensor.shape[1])\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1) # we can tune the learning rate (lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Setup Privacy Engine for DP-SGD\n",
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "model, optimizer, train_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader,\n",
    "    noise_multiplier=5.0,  # we can tune this value (higher means high privacy)\n",
    "    max_grad_norm=0.5, # we can tune this value (lower means high privacy)\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} done\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    preds = outputs.argmax(dim=1).numpy()\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"DP-SGD Logistic Regression Test Accuracy: {acc:.6f}\")\n",
    "\n",
    "epsilon_dpsgd = privacy_engine.get_epsilon(delta=1e-5)\n",
    "print(f\"Achieved epsilon (for DP-SGD): {epsilon_dpsgd:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation for DP-SGD Logistic Regression ===\n",
      "Accuracy: 0.842\n",
      "AUC: 0.892\n",
      "\n",
      "=== Fairness by sex ===\n",
      "    group  positive_rate       TPR       FPR  accuracy\n",
      "0    Male       0.229957  0.555276  0.087549  0.803703\n",
      "1  Female       0.057532  0.394521  0.014644  0.918651\n",
      "\n",
      "Gaps between groups:\n",
      "positive_rate    0.172425\n",
      "TPR              0.160756\n",
      "FPR              0.072905\n",
      "accuracy         0.114949\n",
      "dtype: float64\n",
      "\n",
      "=== Fairness by race ===\n",
      "                group  positive_rate       TPR       FPR  accuracy\n",
      "0               White       0.181120  0.533771  0.059952  0.836152\n",
      "1               Black       0.068349  0.371901  0.024096  0.899054\n",
      "2  Amer-Indian-Eskimo       0.072917  0.375000  0.045455  0.906250\n",
      "3  Asian-Pac-Islander       0.317610  0.686047  0.181034  0.783019\n",
      "4               Other       0.089552  0.500000  0.033898  0.910448\n",
      "\n",
      "Gaps between groups:\n",
      "positive_rate    0.249261\n",
      "TPR              0.314146\n",
      "FPR              0.156938\n",
      "accuracy         0.127429\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results_dp = evaluate_model_full(\n",
    "    name=\"DP-SGD Logistic Regression\",\n",
    "    model=model,                 # PyTorch DP model\n",
    "    X_model_input=X_test_tensor, # tensor for model input\n",
    "    y_true=y_test,\n",
    "    X_sensitive=X_test           # original DataFrame for fairness\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selective DP-SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enricoalmadani/anaconda3/lib/python3.10/site-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive indices: [61, 62, 63, 64, 65, 66, 67]\n",
      "Epoch 1 done\n",
      "Epoch 2 done\n",
      "Epoch 3 done\n",
      "Epoch 4 done\n",
      "Epoch 5 done\n",
      "Epoch 6 done\n",
      "Epoch 7 done\n",
      "Epoch 8 done\n",
      "Epoch 9 done\n",
      "Epoch 10 done\n",
      "Selective DP-SGD Accuracy: 0.842973\n",
      "Achieved epsilon (for Selective DP-SGD): 0.088116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enricoalmadani/anaconda3/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# DP hyperparameters (same as DP config above)\n",
    "noise_multiplier = 5.0\n",
    "max_grad_norm = 0.5\n",
    "delta = 1e-5\n",
    "\n",
    "model1 = LogisticRegressionModel(X_train_tensor.shape[1])\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.1)\n",
    "model1.train() \n",
    "\n",
    "# Attach PrivacyEngine\n",
    "privacy_engine = PrivacyEngine()\n",
    "model1, optimizer, train_loader = privacy_engine.make_private(\n",
    "    module=model1,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    max_grad_norm=max_grad_norm,\n",
    ")\n",
    "\n",
    "# Identify sensitive feature indices\n",
    "sensitive_features = ['sex', 'race']\n",
    "sensitive_indices = []\n",
    "\n",
    "# Extract encoded feature names\n",
    "encoded_feature_names = preprocessor.get_feature_names_out()\n",
    "for idx, name in enumerate(encoded_feature_names):\n",
    "    for sf in sensitive_features:\n",
    "        if sf in name:\n",
    "            sensitive_indices.append(idx)\n",
    "\n",
    "print(\"Sensitive indices:\", sensitive_indices)\n",
    "\n",
    "# Training loop (Selective DP)\n",
    "for epoch in range(10):\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model1(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "\n",
    "        # Selective noise addition\n",
    "        with torch.no_grad():\n",
    "            for name, param in model1.named_parameters():\n",
    "                if \"linear.weight\" in name:\n",
    "                    grad = param.grad\n",
    "                    mask = torch.zeros_like(grad)\n",
    "                    mask[:, sensitive_indices] = 1.0  # sensitive features only\n",
    "\n",
    "                    # Add Gaussian noise only to masked gradients\n",
    "                    noise = torch.normal(\n",
    "                        mean=0,\n",
    "                        std=noise_multiplier * max_grad_norm,\n",
    "                        size=grad.shape,\n",
    "                        device=grad.device\n",
    "                    )\n",
    "                    grad.add_(noise * mask)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} done\")\n",
    "\n",
    "# Evaluate\n",
    "model1.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model1(X_test_tensor)\n",
    "    preds = outputs.argmax(dim=1).numpy()\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"Selective DP-SGD Accuracy: {acc:.6f}\")\n",
    "\n",
    "epsilon = privacy_engine.get_epsilon(delta)\n",
    "print(f\"Achieved epsilon (for Selective DP-SGD): {epsilon:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation for Selective DP-SGD Logistic Regression ===\n",
      "Accuracy: 0.843\n",
      "AUC: 0.893\n",
      "\n",
      "=== Fairness by sex ===\n",
      "    group  positive_rate       TPR       FPR  accuracy\n",
      "0    Male       0.249235  0.588442  0.100748  0.804621\n",
      "1  Female       0.065574  0.438356  0.018131  0.920507\n",
      "\n",
      "Gaps between groups:\n",
      "positive_rate    0.183661\n",
      "TPR              0.150086\n",
      "FPR              0.082617\n",
      "accuracy         0.115887\n",
      "dtype: float64\n",
      "\n",
      "=== Fairness by race ===\n",
      "                group  positive_rate       TPR       FPR  accuracy\n",
      "0               White       0.195754  0.563790  0.069299  0.836872\n",
      "1               Black       0.097792  0.504132  0.038554  0.903260\n",
      "2  Amer-Indian-Eskimo       0.072917  0.375000  0.045455  0.906250\n",
      "3  Asian-Pac-Islander       0.314465  0.697674  0.172414  0.792453\n",
      "4               Other       0.134328  0.625000  0.067797  0.895522\n",
      "\n",
      "Gaps between groups:\n",
      "positive_rate    0.241549\n",
      "TPR              0.322674\n",
      "FPR              0.133860\n",
      "accuracy         0.113797\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results_selective_dp = evaluate_model_full(\n",
    "    name=\"Selective DP-SGD Logistic Regression\",\n",
    "    model=model1,                  \n",
    "    X_model_input=X_test_tensor, \n",
    "    y_true=y_test,\n",
    "    X_sensitive=X_test         \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Privacy-Utility/Fairness Trade-Off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi, I was thinking about exploring how different privacy levels affect model performance by fine-tuning several parameters.\n",
    "\n",
    "There are several ways we can approach this, such as creating a comparison table between regular DP-SGD and selective DP-SGD, or generating plots that show how these parameters impact accuracy and fairness. The setup will involve training both models under the same configurations and then comparing their utility (e.g., accuracy or AUC score) and fairness (e.g., how much accuracy decreases across gender or race groups).\n",
    "\n",
    "The parameters we can vary are:\n",
    "- noise_multiplier (higher values → stronger privacy)\n",
    "- max_grad_norm (lower values → stronger privacy)\n",
    "\n",
    "We’ll focus on these two parameters since they are the most directly related to differential privacy.\n",
    "\n",
    "Constant parameters (kept fixed):\n",
    "- lr (learning rate)\n",
    "- number of epochs\n",
    "- delta (a tunable parameter used in calculating epsilon, the privacy budget. It doesn’t directly affect accuracy, so we don’t need to focus on it.)\n",
    "\n",
    "We could write a function that takes as input lists or ranges of noise_multiplier and max_grad_norm, along with both models (standard DP-SGD and selective DP-SGD) and the baseline non-private model (referred to as clf). The function would store various results for comparison, including:\n",
    "- Overall accuracy\n",
    "- Accuracy by group (e.g., Male, Female, White, Black, etc.)\n",
    "- Drop in accuracy per group (relative to the baseline non-private model, to analyze which groups are more affected by privacy)\n",
    "- Fairness gaps across gender and race\n",
    "- Finally, we can summarize these results in a comparison table and generate visualizations (e.g., plots) to illustrate the effects of different privacy settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
